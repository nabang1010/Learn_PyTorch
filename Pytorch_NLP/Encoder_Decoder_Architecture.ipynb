{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_features, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_features = n_features\n",
    "        self.hidden = None\n",
    "        self.gru = nn.GRU(n_features, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, self.hidden = self.gru(x)\n",
    "        return gru_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_seq = (torch.tensor([[-1, -1], [-1, 1], [1, 1], [1, -1]])\n",
    "            .float()\n",
    "            .view(1, 4, 2))\n",
    "source_seq = full_seq[:, :2]  # first two corners\n",
    "target_seq = full_seq[:, 2:]  # last two corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1.],\n",
       "         [-1.,  1.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.],\n",
       "         [ 1., -1.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "encoder = Encoder(n_features=2, hidden_dim=2)\n",
    "hidden_seq = encoder(source_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0832, -0.0356],\n",
       "         [ 0.3105, -0.5263]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3105, -0.5263]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_final = hidden_seq[:, -1:]\n",
    "hidden_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_features, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_features = n_features\n",
    "        self.gru = nn.GRU(n_features, hidden_dim, batch_first=True)\n",
    "        self.regreesion = nn.Linear(hidden_dim, n_features)\n",
    "\n",
    "    def init_hidden(self, hidden_seq):\n",
    "        self.hidden = hidden_seq[:, -1:].permute(1, 0, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_first_output, self.hidden = self.gru(X, self.hidden)\n",
    "        last_output = batch_first_output[:, -1]\n",
    "        out = self.regreesion(last_output)\n",
    "        return out.view(-1, 1, self.n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden: tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\n",
      "Output: tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "Hidden: tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\n",
      "Output: tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(21)\n",
    "decoder = Decoder(n_features=2, hidden_dim=2)\n",
    "decoder.init_hidden(hidden_seq)\n",
    "input = source_seq[:, -1:]\n",
    "\n",
    "target_len = 2\n",
    "for i in range(target_len):\n",
    "    print(f'Hidden: {decoder.hidden}')\n",
    "    out = decoder(input)\n",
    "    print(f'Output: {out}\\n')\n",
    "    input = out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden: tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\n",
      "Output: tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "Hidden: tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\n",
      "Output: tensor([[[0.2265, 0.4529]]], grad_fn=<ViewBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder.init_hidden(hidden_seq)\n",
    "inputs = source_seq[:, -1:]\n",
    "target_len = 2\n",
    "\n",
    "for i in range(target_len):\n",
    "    print(f'Hidden: {decoder.hidden}')\n",
    "    out = decoder(inputs)\n",
    "    print(f'Output: {out}\\n')\n",
    "    inputs = target_seq[:, i:i+1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random use predict or teaching forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden: tensor([[[ 0.3105, -0.5263]]], grad_fn=<PermuteBackward0>)\n",
      "Output: tensor([[[-0.2339,  0.4702]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "Hidden: tensor([[[ 0.3913, -0.6853]]], grad_fn=<StackBackward0>)\n",
      "Output: tensor([[[-0.0226,  0.4628]]], grad_fn=<ViewBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial hidden state will be encoder's final hidden state\n",
    "decoder.init_hidden(hidden_seq)\n",
    "# Initial data point is the last element of source sequence\n",
    "inputs = source_seq[:, -1:]\n",
    "teacher_forcing_prob = 0.5\n",
    "target_len = 2\n",
    "for i in range(target_len):\n",
    "    print(f'Hidden: {decoder.hidden}')\n",
    "    out = decoder(inputs)\n",
    "    print(f'Output: {out}\\n')\n",
    "    # If it is teacher forcing\n",
    "    if torch.rand(1) <= teacher_forcing_prob:\n",
    "        # Takes the actual element\n",
    "        inputs = target_seq[:, i:i+1]\n",
    "    else:\n",
    "        # Otherwise uses the last predicted output\n",
    "        inputs = out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder + Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Decoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, input_len, target_len, teacher_forcing_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder  \n",
    "        self.input_len = input_len\n",
    "        self.target_len = target_len\n",
    "        self.teacher_forcing_prob = teacher_forcing_prob\n",
    "        self.outputs = None\n",
    "    def init_outputs(self, batch_size):\n",
    "        device = next(self.parameters()).device\n",
    "        self.outputs[:, i:i+1] = torch.zeros(batch_size, self.target_len, self.encoder.n_features).to(device)\n",
    "        \n",
    "    def store_output(self, i, out):\n",
    "        # Stores the output\n",
    "        self.outputs[:, i:i+1, :] = out\n",
    "        \n",
    "    def forward(self, X):\n",
    "        source_seq = X[:, :self.input_len, :]\n",
    "        target_seq = X[:, self.input_len:, :]\n",
    "        self.init_outputs(X.shape[0])\n",
    "        \n",
    "        hidden_seq = self.encoder(source_seq)\n",
    "\n",
    "        self.decoder.init_hidden(hidden_seq)\n",
    "        \n",
    "        dec_inputs = source_seq[:, -1:]\n",
    "        \n",
    "        for i in range(self.target_len):\n",
    "            out = self.decoder(dec_inputs)\n",
    "            self.store_output(i, out)\n",
    "            prob = self.teacher_forcing_prob\n",
    "            if not self.training:\n",
    "                prob = 0\n",
    "            if torch.rand(1) <= prob:\n",
    "                dec_inputs = target_seq[:, i:i+1, :]\n",
    "            else:\n",
    "                dec_inputs = out\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec = Encoder_Decoder(encoder, decoder, input_len=2, target_len=2, teacher_forcing_prob=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_Decoder(\n",
       "  (encoder): Encoder(\n",
       "    (gru): GRU(2, 2, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (gru): GRU(2, 2, batch_first=True)\n",
       "    (regreesion): Linear(in_features=2, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2783713/533513223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menc_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/lba_gnn37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2783713/839489375.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msource_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mhidden_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2783713/839489375.py\u001b[0m in \u001b[0;36minit_outputs\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstore_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "enc_dec(full_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('lba_gnn37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0acbc6efc8d49867015fd0566c44348b9068f0c9a1fa0d66885855ebd09c73fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
